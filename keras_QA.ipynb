{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"keras_QA.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1OtW8gVZ5u20bOEZdsx2GP121AMtd-KNo","authorship_tag":"ABX9TyPgdm79mKEb7XJHNM1nrKQ9"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjdgjGo0Wu2G","executionInfo":{"status":"ok","timestamp":1610335691632,"user_tz":-480,"elapsed":2138,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"f9cd4658-8b97-47f4-84b1-2e01f29be183"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mon Jan 11 03:28:10 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   55C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cOaDX2nur6RL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610335695897,"user_tz":-480,"elapsed":1877,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"e50acbb5-69f8-4520-cd2d-8e06d6f38e24"},"source":["%tensorflow_version 1.x"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fEnNgKkACYms","executionInfo":{"status":"ok","timestamp":1610335708507,"user_tz":-480,"elapsed":9055,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"253a327a-750b-4fcb-a70d-677a6934fc6f"},"source":["!pip3 install nltk\n","import nltk\n","nltk.download('punkt')\n","\n","!pip3 install toposort"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","Collecting toposort\n","  Downloading https://files.pythonhosted.org/packages/f2/7d/55784e894ee0cde2474fb977ffd1651e74e840a9f92e1d847f7e3115d5ec/toposort-1.6-py2.py3-none-any.whl\n","Installing collected packages: toposort\n","Successfully installed toposort-1.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lBgZQn_u43-k"},"source":["#import os\n","#import urllib.request\n","#urllib.request.urlretrieve('https://storage.googleapis.com/albert_models/albert_base_zh.tar.gz','albert_base_zh.tar.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yivAfdrh9DoK","executionInfo":{"status":"ok","timestamp":1610335713097,"user_tz":-480,"elapsed":1525,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"c1772053-8e92-48dd-e577-7b86f4b34be7"},"source":["import sys\n","sys.path.append('/content/drive/MyDrive/colab_data/packages/albert_QA_colab')\n","#sys.path=['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n","print(sys.path)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["['/tensorflow-1.15.2/python3.6', '', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/colab_data/packages/albert_QA_colab']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBPMphH6rX44","executionInfo":{"status":"ok","timestamp":1610335735218,"user_tz":-480,"elapsed":13518,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"2dc757e8-5eb8-40a3-b8e8-990cc5259470"},"source":["import os\n","\n","# AMP要使用 tf.keras \n","os.environ[\"TF_KERAS\"] = \"1\"\n","# 重计算设置\n","import memory_saving_gradients as gc\n","from tensorflow.python.ops import gradients as tf_gradients\n","tf_gradients.gradients = gc.gradients_collection\n","\n","import json\n","import numpy as np\n","from bert4keras.backend import keras, K, tf\n","from bert4keras.models import build_transformer_model\n","from bert4keras.tokenizers import Tokenizer\n","from bert4keras.optimizers import Adam\n","from bert4keras.snippets import sequence_padding, DataGenerator\n","from bert4keras.snippets import open\n","from keras.layers import Layer, Dense, Permute\n","from keras.models import Model\n","from tqdm import tqdm\n","\n","print(tf.__version__)\n","print(tf.test.is_gpu_available())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/colab_data/packages/albert_QA_colab/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","1.15.2\n","True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M634phImDISK","outputId":"c03d2d54-f22e-4fdc-9295-ca0289ea7ecb"},"source":["# 基本信息\n","maxlen = 512\n","epochs = 20\n","batch_size = 64\n","learing_rate = 2e-5\n","\n","\n","# 百度 阅读理解\n","train_data_file1 = '/content/drive/MyDrive/colab_data/data/dureader_robust-data/train.json'  \n","eva_data_file = '/content/drive/MyDrive/colab_data/data/dureader_robust-data/dev.json'\n","eva_script = '/content/drive/MyDrive/colab_data/packages/albert_QA_colab/evaluate/evaluate_dureader.py'\n","\n","# CMRC2018\n","train_data_file2 = '/content/drive/MyDrive/colab_data/data/cmrc2018/cmrc2018_train_dev.json'\n","#eva_data_file = '/content/drive/MyDrive/colab_data/data/cmrc2018/cmrc2018_trial.json'\n","#eva_script = '/content/drive/MyDrive/colab_data/packages/albert_QA_colab/evaluate/evaluate_cmrc2018.py'\n","\n","'''\n","bert4keras 支持的 BERT model_type\n","    'bert': BERT,\n","    'albert': ALBERT,\n","    'albert_unshared': ALBERT_Unshared,\n","    'roberta': BERT,\n","'''\n","\n","# bert配置\n","#model_type = 'bert'\n","#config_path = '/content/drive/MyDrive/colab_data/models/bert_chinese_L-12_H-768_A-12/bert_config.json'\n","#checkpoint_path = '/content/drive/MyDrive/colab_data/models/bert_chinese_L-12_H-768_A-12/bert_model.ckpt'\n","#dict_path = '/content/drive/MyDrive/colab_data/models/bert_chinese_L-12_H-768_A-12/vocab.txt'\n","\n","# albert配置\n","model_type = 'albert'\n","config_path = '/content/drive/MyDrive/colab_data/models/albert_base/albert_config.json'\n","checkpoint_path = '/content/drive/MyDrive/colab_data/models/albert_base/model.ckpt-best'\n","dict_path = '/content/drive/MyDrive/colab_data/models/albert_base/vocab_chinese.txt'\n","\n","# 输出目录\n","output_path = '/content/drive/MyDrive/colab_data/outputs/keras_QA'\n","output_path = '%s/batch%d_max%d_lr%.0e'%(output_path, batch_size, maxlen, learing_rate)\n","\n","\n","# 兼容两个数据集的载入\n","def load_data(filename_list):\n","    D = []\n","    for filename in filename_list:\n","        for d in json.load(open(filename))['data']:\n","            for pp in d['paragraphs']:\n","                for qa in pp['qas']:\n","                    D.append([\n","                        qa['id'], pp['context'], qa['question'],\n","                        [a['text'] for a in qa.get('answers', [])]\n","                    ])\n","    return D\n","\n","\n","# 读取数据, 使用两个数据集一起训练\n","train_data = load_data([train_data_file1, train_data_file2])\n","\n","# 建立分词器\n","tokenizer = Tokenizer(dict_path, do_lower_case=True)\n","\n","\n","def search(pattern, sequence):\n","    \"\"\"从sequence中寻找子串pattern\n","    如果找到，返回第一个下标；否则返回-1。\n","    \"\"\"\n","    n = len(pattern)\n","    for i in range(len(sequence)):\n","        if sequence[i:i + n] == pattern:\n","            return i\n","    return -1\n","\n","\n","class data_generator(DataGenerator):\n","    \"\"\"数据生成器\n","    \"\"\"\n","    def __iter__(self, random=False):\n","        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n","        for is_end, item in self.sample(random):\n","            context, question, answers = item[1:]\n","            token_ids, segment_ids = tokenizer.encode(\n","                question, context, maxlen=maxlen\n","            )\n","            a = np.random.choice(answers)\n","            a_token_ids = tokenizer.encode(a)[0][1:-1]\n","            start_index = search(a_token_ids, token_ids)\n","            if start_index != -1:\n","                labels = [[start_index], [start_index + len(a_token_ids) - 1]]\n","                batch_token_ids.append(token_ids)\n","                batch_segment_ids.append(segment_ids)\n","                batch_labels.append(labels)\n","                if len(batch_token_ids) == self.batch_size or is_end:\n","                    batch_token_ids = sequence_padding(batch_token_ids)\n","                    batch_segment_ids = sequence_padding(batch_segment_ids)\n","                    batch_labels = sequence_padding(batch_labels)\n","                    yield [batch_token_ids, batch_segment_ids], batch_labels\n","                    batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n","\n","\n","# 优化器，使用AMP\n","opt = Adam(learing_rate)\n","opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)\n","\n","# 建立模型，载入权重\n","class MaskedSoftmax(Layer):\n","    \"\"\"在序列长度那一维进行softmax，并mask掉padding部分\n","    \"\"\"\n","    def compute_mask(self, inputs, mask=None):\n","        return None\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            mask = K.cast(mask, K.floatx())\n","            mask = K.expand_dims(mask, 2)\n","            inputs = inputs - (1.0 - mask) * 1e12\n","        return K.softmax(inputs, 1)\n","\n","\n","model = build_transformer_model(\n","    config_path=config_path,\n","    checkpoint_path=checkpoint_path,\n","    model=model_type\n",")\n","\n","\n","output = Dense(2)(model.output)\n","output = MaskedSoftmax()(output)\n","output = Permute((2, 1))(output)\n","\n","model = Model(model.input, output)\n","model.summary()\n","\n","\n","def sparse_categorical_crossentropy(y_true, y_pred):\n","    # y_true需要重新明确一下shape和dtype\n","    y_true = K.reshape(y_true, K.shape(y_pred)[:-1])\n","    y_true = K.cast(y_true, 'int32')\n","    y_true = K.one_hot(y_true, K.shape(y_pred)[2])\n","    # 计算交叉熵\n","    return K.mean(K.categorical_crossentropy(y_true, y_pred))\n","\n","\n","def sparse_accuracy(y_true, y_pred):\n","    # y_true需要重新明确一下shape和dtype\n","    y_true = K.reshape(y_true, K.shape(y_pred)[:-1])\n","    y_true = K.cast(y_true, 'int32')\n","    # 计算准确率\n","    y_pred = K.cast(K.argmax(y_pred, axis=2), 'int32')\n","    return K.mean(K.cast(K.equal(y_true, y_pred), K.floatx()))\n","\n","\n","model.compile(\n","    loss=sparse_categorical_crossentropy,\n","    optimizer=opt,\n","    metrics=[sparse_accuracy]\n",")\n","\n","\n","def extract_answer(question, context, max_a_len=16):\n","    \"\"\"抽取答案函数\n","    \"\"\"\n","    max_q_len = 64\n","    q_token_ids = tokenizer.encode(question, maxlen=max_q_len)[0]\n","    c_token_ids = tokenizer.encode(\n","        context, maxlen=maxlen - len(q_token_ids) + 1\n","    )[0]\n","    token_ids = q_token_ids + c_token_ids[1:]\n","    segment_ids = [0] * len(q_token_ids) + [1] * (len(c_token_ids) - 1)\n","    c_tokens = tokenizer.tokenize(context)[1:-1]\n","    mapping = tokenizer.rematch(context, c_tokens)\n","    probas = model.predict([[token_ids], [segment_ids]])[0]\n","    probas = probas[:, len(q_token_ids):-1]\n","    start_end, score = None, -1\n","    for start, p_start in enumerate(probas[0]):\n","        for end, p_end in enumerate(probas[1]):\n","            if end >= start and end < start + max_a_len:\n","                if p_start * p_end > score:\n","                    start_end = (start, end)\n","                    score = p_start * p_end\n","    start, end = start_end\n","    return context[mapping[start][0]:mapping[end][-1] + 1]\n","\n","\n","def predict_to_file(infile, out_file):\n","    \"\"\"预测结果到文件，方便提交\n","    \"\"\"\n","    fw = open(out_file, 'w', encoding='utf-8')\n","    R = {}\n","    for d in tqdm(load_data([infile])):\n","        a = extract_answer(d[2], d[1])\n","        R[d[0]] = a\n","    R = json.dumps(R, ensure_ascii=False, indent=4)\n","    fw.write(R)\n","    fw.close()\n","\n","\n","def evaluate(filename):\n","    \"\"\"评测函数（官方提供评测脚本evaluate.py）\n","    \"\"\"\n","    predict_to_file(filename, 'evaluate.pred.json')\n","    metrics = json.loads(\n","        os.popen(\n","            'python3 %s %s %s'\n","            % (eva_script, filename, 'evaluate.pred.json')\n","        ).read().strip()\n","    )\n","    return metrics\n","\n","\n","class Evaluator(keras.callbacks.Callback):\n","    \"\"\"评估和保存模型\n","    \"\"\"\n","    def __init__(self):\n","        self.best_val_f1 = 0.\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        metrics = evaluate(eva_data_file)\n","        if float(metrics['F1']) >= self.best_val_f1:\n","            self.best_val_f1 = float(metrics['F1'])\n","            best_path = '%s_F1_%s'%(output_path,metrics['F1'])\n","            os.makedirs(best_path, exist_ok=True)\n","            model.save_weights('%s/best_model.weights' % best_path)\n","        metrics['BEST F1'] = self.best_val_f1\n","        print(metrics)\n","\n","# main()\n","print(\"maxlen: \", maxlen)\n","print(\"epochs: \", epochs)\n","print(\"batch_size: \", batch_size)\n","print(\"learing_rate: \", learing_rate)\n","print(\"train data: \", len(train_data))\n","\n","train_generator = data_generator(train_data, batch_size)\n","evaluator = Evaluator()\n","\n","model.fit_generator(\n","    train_generator.forfit(),\n","    steps_per_epoch=len(train_generator),\n","    epochs=epochs,\n","    callbacks=[evaluator]\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /content/drive/MyDrive/colab_data/packages/albert_QA_colab/bert4keras/models.py:223: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /content/drive/MyDrive/colab_data/packages/albert_QA_colab/bert4keras/models.py:802: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:Entity <bound method MaskedSoftmax.call of <__main__.MaskedSoftmax object at 0x7f64a81845f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method MaskedSoftmax.call of <__main__.MaskedSoftmax object at 0x7f64a81845f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input-Token (InputLayer)        [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","Input-Segment (InputLayer)      [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","Embedding-Token (Embedding)     (None, None, 128)    2704384     Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Embedding-Segment (Embedding)   (None, None, 128)    256         Input-Segment[0][0]              \n","__________________________________________________________________________________________________\n","Embedding-Token-Segment (Add)   (None, None, 128)    0           Embedding-Token[0][0]            \n","                                                                 Embedding-Segment[0][0]          \n","__________________________________________________________________________________________________\n","Embedding-Position (PositionEmb (None, None, 128)    65536       Embedding-Token-Segment[0][0]    \n","__________________________________________________________________________________________________\n","Embedding-Norm (LayerNormalizat (None, None, 128)    256         Embedding-Position[0][0]         \n","__________________________________________________________________________________________________\n","Embedding-Mapping (Dense)       (None, None, 768)    99072       Embedding-Norm[0][0]             \n","__________________________________________________________________________________________________\n","Transformer-MultiHeadSelfAttent (None, None, 768)    2362368     Embedding-Mapping[0][0]          \n","                                                                 Embedding-Mapping[0][0]          \n","                                                                 Embedding-Mapping[0][0]          \n","                                                                 Transformer-FeedForward-Norm[0][0\n","                                                                 Transformer-FeedForward-Norm[0][0\n","                                                                 Transformer-FeedForward-Norm[0][0\n","                                                                 Transformer-FeedForward-Norm[1][0\n","                                                                 Transformer-FeedForward-Norm[1][0\n","                                                                 Transformer-FeedForward-Norm[1][0\n","                                                                 Transformer-FeedForward-Norm[2][0\n","                                                                 Transformer-FeedForward-Norm[2][0\n","                                                                 Transformer-FeedForward-Norm[2][0\n","                                                                 Transformer-FeedForward-Norm[3][0\n","                                                                 Transformer-FeedForward-Norm[3][0\n","                                                                 Transformer-FeedForward-Norm[3][0\n","                                                                 Transformer-FeedForward-Norm[4][0\n","                                                                 Transformer-FeedForward-Norm[4][0\n","                                                                 Transformer-FeedForward-Norm[4][0\n","                                                                 Transformer-FeedForward-Norm[5][0\n","                                                                 Transformer-FeedForward-Norm[5][0\n","                                                                 Transformer-FeedForward-Norm[5][0\n","                                                                 Transformer-FeedForward-Norm[6][0\n","                                                                 Transformer-FeedForward-Norm[6][0\n","                                                                 Transformer-FeedForward-Norm[6][0\n","                                                                 Transformer-FeedForward-Norm[7][0\n","                                                                 Transformer-FeedForward-Norm[7][0\n","                                                                 Transformer-FeedForward-Norm[7][0\n","                                                                 Transformer-FeedForward-Norm[8][0\n","                                                                 Transformer-FeedForward-Norm[8][0\n","                                                                 Transformer-FeedForward-Norm[8][0\n","                                                                 Transformer-FeedForward-Norm[9][0\n","                                                                 Transformer-FeedForward-Norm[9][0\n","                                                                 Transformer-FeedForward-Norm[9][0\n","                                                                 Transformer-FeedForward-Norm[10][\n","                                                                 Transformer-FeedForward-Norm[10][\n","                                                                 Transformer-FeedForward-Norm[10][\n","__________________________________________________________________________________________________\n","Transformer-MultiHeadSelfAttent (None, None, 768)    0           Embedding-Mapping[0][0]          \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward-Norm[0][0\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward-Norm[1][0\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward-Norm[2][0\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward-Norm[3][0\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward-Norm[4][0\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward-Norm[5][0\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward-Norm[6][0\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward-Norm[7][0\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward-Norm[8][0\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward-Norm[9][0\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward-Norm[10][\n","                                                                 Transformer-MultiHeadSelfAttentio\n","__________________________________________________________________________________________________\n","Transformer-MultiHeadSelfAttent (None, None, 768)    1536        Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","__________________________________________________________________________________________________\n","Transformer-FeedForward (FeedFo (None, None, 768)    4722432     Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-MultiHeadSelfAttentio\n","__________________________________________________________________________________________________\n","Transformer-FeedForward-Add (Ad (None, None, 768)    0           Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[0][0]    \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[1][0]    \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[2][0]    \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[3][0]    \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[4][0]    \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[5][0]    \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[6][0]    \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[7][0]    \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[8][0]    \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[9][0]    \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[10][0]   \n","                                                                 Transformer-MultiHeadSelfAttentio\n","                                                                 Transformer-FeedForward[11][0]   \n","__________________________________________________________________________________________________\n","Transformer-FeedForward-Norm (L (None, None, 768)    1536        Transformer-FeedForward-Add[0][0]\n","                                                                 Transformer-FeedForward-Add[1][0]\n","                                                                 Transformer-FeedForward-Add[2][0]\n","                                                                 Transformer-FeedForward-Add[3][0]\n","                                                                 Transformer-FeedForward-Add[4][0]\n","                                                                 Transformer-FeedForward-Add[5][0]\n","                                                                 Transformer-FeedForward-Add[6][0]\n","                                                                 Transformer-FeedForward-Add[7][0]\n","                                                                 Transformer-FeedForward-Add[8][0]\n","                                                                 Transformer-FeedForward-Add[9][0]\n","                                                                 Transformer-FeedForward-Add[10][0\n","                                                                 Transformer-FeedForward-Add[11][0\n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, None, 2)      1538        Transformer-FeedForward-Norm[11][\n","__________________________________________________________________________________________________\n","masked_softmax (MaskedSoftmax)  (None, None, 2)      0           dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","permute (Permute)               (None, 2, None)      0           masked_softmax[0][0]             \n","==================================================================================================\n","Total params: 9,958,914\n","Trainable params: 9,958,914\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","maxlen:  512\n","epochs:  20\n","batch_size:  64\n","learing_rate:  2e-05\n","train data:  27881\n","Epoch 1/20\n","WARNING:tensorflow:From /content/drive/MyDrive/colab_data/packages/albert_QA_colab/memory_saving_gradients.py:72: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n","Instructions for updating:\n","Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n","ts_all 1=  4044\n","WARNING:tensorflow:From /content/drive/MyDrive/colab_data/packages/albert_QA_colab/memory_saving_gradients.py:99: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","checkpoints =  24\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","435/436 [============================>.] - ETA: 4s - loss: 1.9752 - sparse_accuracy: 0.5061"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1417/1417 [01:05<00:00, 21.55it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["{'F1': '79.521', 'EM': '66.690', 'TOTAL': 1417, 'SKIP': 0, 'BEST F1': 79.521}\n","\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r436/436 [==============================] - 1986s 5s/step - loss: 1.9731 - sparse_accuracy: 0.5064\n","Epoch 2/20\n","435/436 [============================>.] - ETA: 4s - loss: 1.0199 - sparse_accuracy: 0.6880"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1417/1417 [01:03<00:00, 22.42it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["{'F1': '82.000', 'EM': '69.725', 'TOTAL': 1417, 'SKIP': 0, 'BEST F1': 82.0}\n","\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r436/436 [==============================] - 1962s 5s/step - loss: 1.0200 - sparse_accuracy: 0.6879\n","Epoch 3/20\n","435/436 [============================>.] - ETA: 4s - loss: 0.7861 - sparse_accuracy: 0.7498"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1417/1417 [01:06<00:00, 21.37it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["{'F1': '81.366', 'EM': '68.948', 'TOTAL': 1417, 'SKIP': 0, 'BEST F1': 82.0}\n","\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r436/436 [==============================] - 1958s 4s/step - loss: 0.7854 - sparse_accuracy: 0.7499\n","Epoch 4/20\n","300/436 [===================>..........] - ETA: 9:48 - loss: 0.6250 - sparse_accuracy: 0.7994"],"name":"stdout"}]}]}